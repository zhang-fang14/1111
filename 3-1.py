import os
import cv2
import numpy as np
from imgaug import augmenters as iaa
from icrawler.builtin import GoogleImageCrawler

# ========== ç¬¬ä¸€éƒ¨åˆ†ï¼šå›¾åƒé‡‡é›† ==========

def download_images(keyword, num_images=60, save_dir='dataset_raw'):
    os.makedirs(save_dir, exist_ok=True)
    crawler = GoogleImageCrawler(storage={'root_dir': save_dir})
    crawler.crawl(keyword=keyword, max_num=num_images, min_size=(128, 128))

# ========== ç¬¬äºŒéƒ¨åˆ†ï¼šå›¾åƒå¢å¼º ==========

def augment_images(input_dir='dataset_raw', output_dir='dataset_augmented', augment_per_image=4):
    os.makedirs(output_dir, exist_ok=True)

    # å¢å¼ºæµæ°´çº¿å®šä¹‰
    seq = iaa.Sequential([
        iaa.Fliplr(0.5),                          # æ°´å¹³ç¿»è½¬
        iaa.Affine(
            scale=(0.8, 1.2),                    # ç¼©æ”¾
            translate_percent=(-0.1, 0.1),       # å¹³ç§»
            rotate=(-15, 15),                    # æ—‹è½¬
        ),
        iaa.AddToHueAndSaturation((-20, 20)),    # è‰²å½©æ‰°åŠ¨
        iaa.Crop(percent=(0, 0.1)),              # éšæœºè£å‰ª
    ])

    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
    count = 0

    for file in image_files:
        path = os.path.join(input_dir, file)
        img = cv2.imread(path)
        if img is None:
            print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒï¼š{file}")
            continue

        # å°†å›¾åƒå¢å¼ºå¤šæ¬¡
        for i in range(augment_per_image):
            aug_img = seq(image=img)
            out_path = os.path.join(output_dir, f"{count:04d}.jpg")
            cv2.imwrite(out_path, aug_img)
            count += 1

    print(f"\nâœ… å›¾åƒå¢å¼ºå®Œæˆï¼šå…±ç”Ÿæˆ {count} å¼ å¢å¼ºå›¾åƒï¼Œå·²ä¿å­˜è‡³ï¼š{output_dir}")

# ========== ä¸»ç¨‹åºå…¥å£ ==========

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹å›¾åƒä¸‹è½½å’Œå¢å¼ºä»»åŠ¡...\n")

    # æ­¥éª¤ 1ï¼šçˆ¬å–ä¸å°‘äº 50 å¼ å›¾åƒ
    keyword = "rehabilitation training"
    print(f"ğŸ” æ­£åœ¨ä¸‹è½½å›¾åƒï¼š'{keyword}' ...")
    download_images(keyword=keyword, num_images=60, save_dir='dataset_raw')

    # æ­¥éª¤ 2ï¼šå¢å¼ºä¸ºä¸å°‘äº 200 å¼ å›¾åƒï¼ˆæ¯å¼ å›¾å¢å¼º 4 æ¬¡ï¼‰
    print("\nğŸ§ª å¼€å§‹å›¾åƒå¢å¼º...")
    augment_images(input_dir='dataset_raw', output_dir='dataset_augmented', augment_per_image=4)

    print("\nâœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚ä½ å¯ä»¥åœ¨ 'dataset_augmented/' æ–‡ä»¶å¤¹ä¸­æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®é›†ã€‚")
